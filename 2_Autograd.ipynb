{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:19:31.845095Z",
     "start_time": "2021-06-30T04:19:31.517118Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd is needed to calculate gradient in back propogation of any neural network. Autograd is automatic differentiation engine in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:19:32.896460Z",
     "start_time": "2021-06-30T04:19:32.891945Z"
    }
   },
   "outputs": [],
   "source": [
    "# requires_grad setting to True means we need to compute gradient after every operation its been used in\n",
    "a = torch.tensor([5.], requires_grad=True)\n",
    "b= torch.tensor([6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:19:49.769559Z",
     "start_time": "2021-06-30T04:19:49.765162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:19:50.447746Z",
     "start_time": "2021-06-30T04:19:50.443396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:19:51.273243Z",
     "start_time": "2021-06-30T04:19:51.268257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = a**3 - b**2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:16:56.233848Z",
     "start_time": "2021-06-30T04:16:56.231255Z"
    }
   },
   "source": [
    "Suppose y is loss. We need to calculate \n",
    "- dy/da => 3*(a**2) => 75\n",
    "- dy/db => -2*b => -12\n",
    "\n",
    "Using Autograd we can compute it auomatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:19:55.934092Z",
     "start_time": "2021-06-30T04:19:55.931469Z"
    }
   },
   "outputs": [],
   "source": [
    "a.grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its none in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:20:24.179239Z",
     "start_time": "2021-06-30T04:20:23.936469Z"
    }
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:20:27.045251Z",
     "start_time": "2021-06-30T04:20:27.040245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:20:30.621239Z",
     "start_time": "2021-06-30T04:20:30.616134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:21:49.891036Z",
     "start_time": "2021-06-30T04:21:49.884508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4472],\n",
       "         [ 0.2763],\n",
       "         [-1.2931],\n",
       "         [ 0.4786],\n",
       "         [-2.3143],\n",
       "         [-0.3986],\n",
       "         [ 0.5176],\n",
       "         [ 1.4266],\n",
       "         [-1.8022],\n",
       "         [-0.4652]], requires_grad=True),\n",
       " tensor([-1.2512], requires_grad=True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(10,1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad = True)\n",
    "W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:22:09.792646Z",
     "start_time": "2021-06-30T04:22:09.787704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9973, -0.5639,  1.4689,  0.0625, -0.1191, -0.2536, -0.4693, -0.2688,\n",
       "         -1.9155,  0.0652]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:22:33.008724Z",
     "start_time": "2021-06-30T04:22:33.003735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7885]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.matmul(x, W) + b\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:22:41.628114Z",
     "start_time": "2021-06-30T04:22:41.624697Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = 1 - output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:22:55.470881Z",
     "start_time": "2021-06-30T04:22:55.468035Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:23:05.769510Z",
     "start_time": "2021-06-30T04:23:05.764252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9973],\n",
       "         [ 0.5639],\n",
       "         [-1.4689],\n",
       "         [-0.0625],\n",
       "         [ 0.1191],\n",
       "         [ 0.2536],\n",
       "         [ 0.4693],\n",
       "         [ 0.2688],\n",
       "         [ 1.9155],\n",
       "         [-0.0652]]),\n",
       " tensor([-1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad, b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update the weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:24:01.834981Z",
     "start_time": "2021-06-30T04:24:01.831785Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.no_grad is a way of telling torch to not compute gradients for this operation~\n",
    "with torch.no_grad(): \n",
    "    W -= 0.001 * W.grad.data\n",
    "    b -= 0.001 * b.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:25:22.121412Z",
     "start_time": "2021-06-30T04:25:22.116188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4492],\n",
       "         [ 0.2757],\n",
       "         [-1.2917],\n",
       "         [ 0.4787],\n",
       "         [-2.3144],\n",
       "         [-0.3988],\n",
       "         [ 0.5171],\n",
       "         [ 1.4263],\n",
       "         [-1.8041],\n",
       "         [-0.4651]], requires_grad=True),\n",
       " tensor([-1.2502], requires_grad=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updated weights and bias\n",
    "W, b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
